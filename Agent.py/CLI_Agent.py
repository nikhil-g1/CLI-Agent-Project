# -*- coding: utf-8 -*-
"""CLI_Tool.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dZC3bhbse0uBxUMtFGIKUvIfDXU3YHP4
"""

import json
import os
from datetime import datetime
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from peft import PeftModel, PeftConfig

#Loading model with LoRa adapter
base_model = "Qwen/Qwen2-0.5B"
adapter_path = "lora-qwen2-adapter"

tokenizer = AutoTokenizer.from_pretrained(base_model)
model = AutoModelForCausalLM.from_pretrained(base_model)
model = PeftModel.from_pretrained(model, adapter_path)

#Creating text generation pipeline
gen = pipeline("text-generation", model=model, tokenizer=tokenizer)

#Func. to log entries into json file
def log_trace(entry):
  os.makedirs("logs", exist_ok=True)
  with open("logs/trace.jsonl", "a") as f:
    f.write(json.dumps(entry) + "\n")

#Func. to generate step by step plan
def plan_and_execute(instruction):
  result = gen(f"Step-by-step plan for: {instruction}\n")[0]["generated_text"]
  steps = result.strip().split("\n")
  print("\nGenerated Plan:")
  for step in steps:
    print("-", step)
    if step.startswith("`") and step.endswith("`"):
      cmd = step.strip("`")
      print(f"[DRY RUN] echo {cmd}")
    log_trace({"timestamp": datetime.now().isoformat(), "step": step})

if __name__== "__main__":
  import sys
  instr = input("Enter your instruction: ")
  plan_and_execute(instr)